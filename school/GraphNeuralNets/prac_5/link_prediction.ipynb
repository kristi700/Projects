{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import negative_sampling, add_self_loops, remove_self_loops, train_test_split_edges\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "class LinkPredictionGNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2, \n",
    "                 layer_type='GCN', dropout=0.5):\n",
    "        super().__init__()\n",
    "        conv_dict = {'GCN': GCNConv, 'GAT': GATConv, 'SAGE': SAGEConv}\n",
    "        conv_layer = conv_dict[layer_type]\n",
    "        \n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(conv_layer(in_channels, hidden_channels))\n",
    "        \n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(conv_layer(hidden_channels, hidden_channels))\n",
    "            \n",
    "        self.convs.append(conv_layer(hidden_channels, out_channels))\n",
    "        \n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def encode(self, x, edge_index):\n",
    "        \"\"\"Encode node features into embeddings\"\"\"\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, z, edge_index):\n",
    "        \"\"\"Compute edge scores from node embeddings\"\"\"\n",
    "        src, dst = edge_index\n",
    "        return (z[src] * z[dst]).sum(dim=1)\n",
    "    \n",
    "    def decode_all(self, z):\n",
    "        \"\"\"Decode all possible edges\"\"\"\n",
    "        return torch.matmul(z, z.t())\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        z = self.encode(x, edge_index)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_link_pred(model, optimizer, data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    z = model.encode(data.x, data.train_pos_edge_index)\n",
    "    \n",
    "    pos_edge_index = data.train_pos_edge_index\n",
    "    \n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=pos_edge_index,\n",
    "        num_nodes=data.num_nodes,\n",
    "        num_neg_samples=pos_edge_index.size(1))\n",
    "    \n",
    "    pos_score = model.decode(z, pos_edge_index)\n",
    "    neg_score = model.decode(z, neg_edge_index)\n",
    "    \n",
    "    scores = torch.cat([pos_score, neg_score], dim=0)\n",
    "    labels = torch.cat([torch.ones(pos_score.size(0)), \n",
    "                       torch.zeros(neg_score.size(0))], dim=0)\n",
    "    \n",
    "    loss = F.binary_cross_entropy_with_logits(scores, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_link_pred(model, data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.train_pos_edge_index)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    pos_edge_index = data.test_pos_edge_index\n",
    "    neg_edge_index = data.test_neg_edge_index\n",
    "    \n",
    "    pos_score = model.decode(z, pos_edge_index)\n",
    "    neg_score = model.decode(z, neg_edge_index)\n",
    "    \n",
    "    scores = torch.cat([pos_score, neg_score], dim=0)\n",
    "    labels = torch.cat([torch.ones(pos_score.size(0)), \n",
    "                       torch.zeros(neg_score.size(0))], dim=0)\n",
    "    \n",
    "    scores_np = scores.cpu().numpy()\n",
    "    labels_np = labels.cpu().numpy()\n",
    "    \n",
    "    results['test_auc'] = roc_auc_score(labels_np, scores_np)\n",
    "    results['test_ap'] = average_precision_score(labels_np, scores_np)\n",
    "    \n",
    "    pos_edge_index = data.val_pos_edge_index\n",
    "    neg_edge_index = data.val_neg_edge_index\n",
    "    \n",
    "    pos_score = model.decode(z, pos_edge_index)\n",
    "    neg_score = model.decode(z, neg_edge_index)\n",
    "    \n",
    "    scores = torch.cat([pos_score, neg_score], dim=0)\n",
    "    labels = torch.cat([torch.ones(pos_score.size(0)), \n",
    "                       torch.zeros(neg_score.size(0))], dim=0)\n",
    "    \n",
    "    scores_np = scores.cpu().numpy()\n",
    "    labels_np = labels.cpu().numpy()\n",
    "    \n",
    "    results['val_auc'] = roc_auc_score(labels_np, scores_np)\n",
    "    results['val_ap'] = average_precision_score(labels_np, scores_np)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def run_experiment(dataset_name, gnn_type, use_self_loops=False, embedding_dim=64):\n",
    "    dataset = Planetoid(root='.', name=dataset_name)\n",
    "    data = dataset[0]\n",
    "    \n",
    "    data = train_test_split_edges(data)\n",
    "    \n",
    "    if use_self_loops:\n",
    "        data.train_pos_edge_index, _ = add_self_loops(data.train_pos_edge_index, \n",
    "                                                      num_nodes=data.num_nodes)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = LinkPredictionGNN(\n",
    "        in_channels=dataset.num_features,\n",
    "        hidden_channels=128,\n",
    "        out_channels=embedding_dim,\n",
    "        num_layers=2,\n",
    "        layer_type=gnn_type\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    data = data.to(device)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_aucs = []\n",
    "    \n",
    "    best_val_auc = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, 201):\n",
    "        loss = train_link_pred(model, optimizer, data)\n",
    "        train_losses.append(loss)\n",
    "        \n",
    "        results = test_link_pred(model, data)\n",
    "        val_aucs.append(results['val_auc'])\n",
    "        \n",
    "        if results['val_auc'] > best_val_auc:\n",
    "            best_val_auc = results['val_auc']\n",
    "            best_model = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val AUC: {results[\"val_auc\"]:.4f}, '\n",
    "                  f'Val AP: {results[\"val_ap\"]:.4f}')\n",
    "    \n",
    "    model.load_state_dict(best_model)\n",
    "    model = model.to(device)\n",
    "    final_results = test_link_pred(model, data)\n",
    "    \n",
    "    loops_str = \"with\" if use_self_loops else \"without\"\n",
    "    print(f\"\\nFinal Results for {dataset_name} with {gnn_type} {loops_str} self-loops:\")\n",
    "    print(f\"Test AUC: {final_results['test_auc']:.4f}\")\n",
    "    print(f\"Test AP: {final_results['test_ap']:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_aucs': val_aucs,\n",
    "        'final_results': final_results\n",
    "    }\n",
    "\n",
    "def compare_self_loops():\n",
    "    datasets = ['Cora', 'PubMed']\n",
    "    gnn_types = ['GCN', 'GAT', 'SAGE']\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for dataset_name in datasets:\n",
    "        all_results[dataset_name] = {}\n",
    "        for gnn_type in gnn_types:\n",
    "            print(f\"\\nRunning {gnn_type} on {dataset_name} without self-loops...\")\n",
    "            without_loops = run_experiment(dataset_name, gnn_type, use_self_loops=False)\n",
    "            \n",
    "            print(f\"\\nRunning {gnn_type} on {dataset_name} with self-loops...\")\n",
    "            with_loops = run_experiment(dataset_name, gnn_type, use_self_loops=True)\n",
    "            \n",
    "            all_results[dataset_name][gnn_type] = {\n",
    "                'without_loops': without_loops,\n",
    "                'with_loops': with_loops\n",
    "            }\n",
    "    \n",
    "    for dataset_name in datasets:\n",
    "        fig, axes = plt.subplots(len(gnn_types), 2, figsize=(15, 5*len(gnn_types)))\n",
    "        fig.suptitle(f'Link Prediction Performance on {dataset_name}', fontsize=16)\n",
    "        \n",
    "        for i, gnn_type in enumerate(gnn_types):\n",
    "            results = all_results[dataset_name][gnn_type]\n",
    "            \n",
    "            axes[i, 0].plot(results['without_loops']['train_losses'], label='Without Self-Loops')\n",
    "            axes[i, 0].plot(results['with_loops']['train_losses'], label='With Self-Loops')\n",
    "            axes[i, 0].set_title(f'{gnn_type} - Training Loss')\n",
    "            axes[i, 0].set_xlabel('Epoch')\n",
    "            axes[i, 0].set_ylabel('Loss')\n",
    "            axes[i, 0].legend()\n",
    "            \n",
    "            axes[i, 1].plot(results['without_loops']['val_aucs'], label='Without Self-Loops')\n",
    "            axes[i, 1].plot(results['with_loops']['val_aucs'], label='With Self-Loops')\n",
    "            axes[i, 1].set_title(f'{gnn_type} - Validation AUC')\n",
    "            axes[i, 1].set_xlabel('Epoch')\n",
    "            axes[i, 1].set_ylabel('AUC')\n",
    "            axes[i, 1].legend()\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plt.savefig(f'{dataset_name}_link_prediction_comparison.png')\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"\\n--- Summary Results ---\")\n",
    "    for dataset_name in datasets:\n",
    "        print(f\"\\n{dataset_name} Dataset\")\n",
    "        for gnn_type in gnn_types:\n",
    "            results = all_results[dataset_name][gnn_type]\n",
    "            without_auc = results['without_loops']['final_results']['test_auc']\n",
    "            with_auc = results['with_loops']['final_results']['test_auc']\n",
    "            print(f\"{gnn_type}: Without self-loops AUC: {without_auc:.4f}, \"\n",
    "                  f\"With self-loops AUC: {with_auc:.4f}, \"\n",
    "                  f\"Improvement: {(with_auc - without_auc) * 100:.2f}%\")\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment('Cora', 'GCN', use_self_loops=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
