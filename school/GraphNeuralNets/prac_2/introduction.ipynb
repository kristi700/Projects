{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import networkx as nx\n",
    "\n",
    "from torch_geometric.nn import MLP\n",
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='data/Cora', name='Cora')\n",
    "G = torch_geometric.utils.to_networkx(dataset[0], to_undirected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_dict = nx.degree_centrality(G)\n",
    "betweenness_dict = nx.betweenness_centrality(G)\n",
    "eigenvector_dict = nx.eigenvector_centrality(G, max_iter=1000)\n",
    "closeness_dict = nx.closeness_centrality(G)\n",
    "clustering_dict = nx.clustering(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = range(data.num_nodes)\n",
    "degree_feat = torch.tensor([degree_dict[i] for i in indices]).unsqueeze(1)\n",
    "betweenness_feat = torch.tensor([betweenness_dict[i] for i in indices]).unsqueeze(1)\n",
    "eigenvector_feat = torch.tensor([eigenvector_dict[i] for i in indices]).unsqueeze(1)\n",
    "closeness_feat = torch.tensor([closeness_dict[i] for i in indices]).unsqueeze(1)\n",
    "clustering_feat = torch.tensor([clustering_dict[i] for i in indices]).unsqueeze(1)\n",
    "\n",
    "data.x = torch.cat([data.x,degree_feat,betweenness_feat,eigenvector_feat,closeness_feat,clustering_feat], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1438], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = data.train_mask\n",
    "test_mask = data.test_mask\n",
    "val_mask = data.val_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(in_channels=data.x.size(1), hidden_channels=32, out_channels=dataset.num_classes, num_layers=2, dropout=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10; Training loss: 0.5711208581924438\n",
      "Epoch: 10; Val loss: 1.6899352073669434\n",
      "Epoch: 20; Training loss: 0.1952216923236847\n",
      "Epoch: 20; Val loss: 1.4549846649169922\n",
      "Epoch: 30; Training loss: 0.13749440014362335\n",
      "Epoch: 30; Val loss: 1.4336274862289429\n",
      "Epoch: 40; Training loss: 0.08225499093532562\n",
      "Epoch: 40; Val loss: 1.4863533973693848\n",
      "Epoch: 50; Training loss: 0.05347158759832382\n",
      "Epoch: 50; Val loss: 1.5378046035766602\n",
      "Epoch: 60; Training loss: 0.03344025835394859\n",
      "Epoch: 60; Val loss: 1.5725793838500977\n",
      "Epoch: 70; Training loss: 0.028133947402238846\n",
      "Epoch: 70; Val loss: 1.5890628099441528\n",
      "Epoch: 80; Training loss: 0.05381563678383827\n",
      "Epoch: 80; Val loss: 1.6063263416290283\n",
      "Epoch: 90; Training loss: 0.010545135475695133\n",
      "Epoch: 90; Val loss: 1.6337193250656128\n",
      "Epoch: 100; Training loss: 0.026129113510251045\n",
      "Epoch: 100; Val loss: 1.6395823955535889\n",
      "Epoch: 110; Training loss: 0.020222874358296394\n",
      "Epoch: 110; Val loss: 1.6626200675964355\n",
      "Epoch: 120; Training loss: 0.02631177380681038\n",
      "Epoch: 120; Val loss: 1.689312219619751\n",
      "Epoch: 130; Training loss: 0.017961781471967697\n",
      "Epoch: 130; Val loss: 1.7294094562530518\n",
      "Epoch: 140; Training loss: 0.03744344413280487\n",
      "Epoch: 140; Val loss: 1.7644120454788208\n",
      "Epoch: 150; Training loss: 0.012312336824834347\n",
      "Epoch: 150; Val loss: 1.7825970649719238\n",
      "Epoch: 160; Training loss: 0.01242069248110056\n",
      "Epoch: 160; Val loss: 1.7797669172286987\n",
      "Epoch: 170; Training loss: 0.009659797884523869\n",
      "Epoch: 170; Val loss: 1.784683108329773\n",
      "Epoch: 180; Training loss: 0.02260349690914154\n",
      "Epoch: 180; Val loss: 1.7946116924285889\n",
      "Epoch: 190; Training loss: 0.015326605178415775\n",
      "Epoch: 190; Val loss: 1.7742551565170288\n",
      "Epoch: 200; Training loss: 0.010363534092903137\n",
      "Epoch: 200; Val loss: 1.7901890277862549\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 201):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred=model(data.x[train_mask])\n",
    "    loss=criterion(pred, data.y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i %10 ==0 and verbose > 0:\n",
    "        print(f\"Epoch: {i}; Training loss: {loss}\")\n",
    "\n",
    "    if i %10 ==0 and verbose > 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred=model(data.x[val_mask])\n",
    "            loss=criterion(pred, data.y[val_mask]) \n",
    "            print(f\"Epoch: {i}; Val loss: {loss}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5350\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(data.x)\n",
    "    test_preds = logits[test_mask].argmax(dim=1)\n",
    "    test_acc = (test_preds == data.y[test_mask]).float().mean().item()\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
